
<!DOCTYPE html>
<html>

<head lang="en">
    <meta charset="UTF-8">
    <meta http-equiv="x-ua-compatible" content="ie=edge">

    <title>UPNeRF</title>

    <meta name="description" content="">
    <meta name="viewport" content="width=device-width, initial-scale=1">

    <meta property="og:image" content="https://yuliangguo.github.io/upnerf/img/nottingham.jpg">
    <meta property="og:image:type" content="image/png">
    <meta property="og:image:width" content="1296">
    <meta property="og:image:height" content="840">
    <meta property="og:type" content="website" />
    <meta property="og:url" content="https://yuliangguo.github.io/upnerf/"/>
    <meta property="og:title" content="UPNeRF: A Unified Framework for Monocular 3D Object Reconstruction and Pose Estimation" />
    <meta property="og:description" content="Monocular 3D reconstruction for categorical objects heavily relies on accurately perceiving each object’s pose. While gradient-based optimization within a NeRF framework updates initially given poses, this paper highlights that such a scheme fails when the initial pose even moderately deviates from the true pose. Consequently, existing methods often depend on a third-party 3D object to provide an initial object pose, leading to increased complexity and generalization issues. To address these challenges, we present UPNeRF, a Unified framework integrating Pose estimation and NeRF-based reconstruction, bringing us closer to real-time monocular 3D object reconstruction. UPNeRF decouples the object’s dimension estimation and pose refinement to resolve the scale-depth ambiguity, and introduces an effective projected-box representation that generalizes well cross different domains. While using a dedicated pose estimator that smoothly integrates into an object-centric NeRF , UPNeRF is free from external 3D detectors. UPNeRF achieves state-of-the-art results in both reconstruction and pose estimation tasks on the nuScenes dataset. Furthermore, UPNeRF exhibits exceptional Cross-dataset generalization on the KITTI and Waymo datasets, surpassing prior methods with up to 50% reduction in rotation and translation error." />

    <meta name="twitter:card" content="summary_large_image" />
    <meta name="twitter:title" content="UPNeRF: A Unified Framework for Monocular 3D Object Reconstruction and Pose Estimation" />
    <meta name="twitter:description" content="Monocular 3D reconstruction for categorical objects heavily relies on accurately perceiving each object’s pose. While gradient-based optimization within a NeRF framework updates initially given poses, this paper highlights that such a scheme fails when the initial pose even moderately deviates from the true pose. Consequently, existing methods often depend on a third-party 3D object to provide an initial object pose, leading to increased complexity and generalization issues. To address these challenges, we present UPNeRF, a Unified framework integrating Pose estimation and NeRF-based reconstruction, bringing us closer to real-time monocular 3D object reconstruction. UPNeRF decouples the object’s dimension estimation and pose refinement to resolve the scale-depth ambiguity, and introduces an effective projected-box representation that generalizes well cross different domains. While using a dedicated pose estimator that smoothly integrates into an object-centric NeRF , UPNeRF is free from external 3D detectors. UPNeRF achieves state-of-the-art results in both reconstruction and pose estimation tasks on the nuScenes dataset. Furthermore, UPNeRF exhibits exceptional Cross-dataset generalization on the KITTI and Waymo datasets, surpassing prior methods with up to 50% reduction in rotation and translation error." />
    <meta name="twitter:image" content="https://yuliangguo.github.io/upnerf/img/teaser.jpg" />


<link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>⚡</text></svg>">

    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.5/css/bootstrap.min.css">
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.4.0/css/font-awesome.min.css">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/codemirror/5.8.0/codemirror.min.css">
    <link rel="stylesheet" href="css/app.css">

    <link rel="stylesheet" href="css/bootstrap.min.css">

    <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.11.3/jquery.min.js"></script>
    <script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.5/js/bootstrap.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/codemirror/5.8.0/codemirror.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/1.5.3/clipboard.min.js"></script>
    
    <script src="js/app.js"></script>
    <script src="js/video_comparison.js"></script>
</head>

<body>
    <div class="container" id="main">
        <div class="row">
            <h2 class="col-md-10 text-center col-md-offset-1">
                <b>UPNeRF</b>: A Unified Framework for Monocular 3D Object Reconstruction and Pose Estimation</br> 
                <!-- <small>
                ICCV 2023 (Oral Presentation, Best Paper Finalist)
                </small> -->
            </h2>
        </div>
        <div class="row">
            <div class="col-md-12 text-center">
                <ul class="list-inline">
                    <li>
                        <a href="https://yuliangguo.github.io/">
                          Yuliang Guo
                        </a>
                    </li>
                    <li>
                        <a href="https://sites.google.com/view/abhinavkumar">
                            Abhinav Kumar
                        </a>
                    </li>
                    <li>
                        <a href="https://scholar.google.com/citations?user=EAC-8m0AAAAJ&hl=zh-CN">
                          Cheng Zhao
                        </a>
                    </li>
                    <li>
                        <a href="https://scholar.google.com/citations?user=UfGLSTkAAAAJ&hl=en">
                          Ruoyu Wang
                        </a>
                    </li>
                    <li>
                        <a href="https://scholar.google.com/citations?user=cL4bNBwAAAAJ&hl=en">
                          Xinyu Huang
                        </a>
                    </li>
                    <li>
                        <a href="https://sites.google.com/site/liurenshomepage/">
                          Liu Ren
                        </a>
                    </li>
                    </br>Bosch AI North America
                </ul>
            </div>
        </div>


        <div class="row">
                <div class="col-md-6 col-md-offset-3 text-center">
                    <ul class="nav nav-pills nav-justified">
                        <li>
                            <a href="TODO">
                            <image src="img/upnerf_paper_image.jpg" height="60px">
                                <h4><strong>Paper</strong></h4>
                            </a>
                        </li>
                        <!-- <li>
                            <a href="https://www.youtube.com/watch?v=xrrhynRzC8k">
                            <image src="img/youtube_icon.png" height="60px">
                                <h4><strong>Video</strong></h4>
                            </a>
                        </li> -->
                        <li>
                            <a href="https://github.com/yuliangguo/nerf-auto-driving">
                            <image src="img/github_pad.png" height="60px">
                                <h4><strong>Code (Coming Soon)</strong></h4>
                            </a>
                        </li>
                    </ul>
                </div>
        </div>

<br>
        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <div class="text-center">
                    <img src='img/pipeline_overview.png' width=80%>
                </div>
            </div>
        </div>


        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    Abstract
                </h3>
                <p class="text-justify">
                    Monocular 3D reconstruction for categorical objects heavily relies on accurately perceiving each object’s pose. While gradient-based optimization within a NeRF framework updates initially given poses, this paper highlights that such a scheme fails when the initial pose even moderately deviates from the true pose. Consequently, existing methods often depend on a third-party 3D object to provide an initial object pose, leading to increased complexity and generalization issues. To address these challenges, we present UPNeRF, a Unified framework integrating Pose estimation and NeRF-based reconstruction, bringing us closer to real-time monocular 3D object reconstruction. UPNeRF decouples the object’s dimension estimation and pose refinement to resolve the scale-depth ambiguity, and introduces an effective projected-box representation that generalizes well cross different domains. While using a dedicated pose estimator that smoothly integrates into an object-centric NeRF , UPNeRF is free from external 3D detectors. UPNeRF achieves state-of-the-art results in both reconstruction and pose estimation tasks on the nuScenes dataset. Furthermore, UPNeRF exhibits exceptional Cross-dataset generalization on the KITTI and Waymo datasets, surpassing prior methods with up to 50% reduction in rotation and translation error.
                </p>
            </div>
        </div>

<br>
        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    Pipeline
                </h3>
                <div class="text-center">
                    <!-- <div style="position:relative;padding-top:56.25%;"> -->
                        <img src='img/pipeline_train_test.png' width=100%>
                    <!-- </div> -->
                </div>
                <p class="text-justify">
                    UPNeRF unifies pose estimation and NeRF. The pose
estimation module enables UPNeRF to work for objects in diverse poses without
external 3D detectors. The increase of complexity only constitutes a few MLP layers.
                </p>
            </div>
        </div>
<br>
        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    Camera-Invariant Pose Estimation Module
                </h3>
                <div class="text-center">
                    <!-- <div style="position:relative;padding-top:56.25%;"> -->
                        <img src='img/pose_refine_illus.png' width=70%>
                    <!-- </div> -->
                </div>
                <p class="text-justify">
                    The pose estimation module of UPNeRF
iteratively updates the object’s pose while preserving scale. It takes the projection
of 3D box corners as a visual representation of the input pose and estimate the pose
update via comparing it to observed image in a latent embedding space. These designs
handle scale-depth ambiguity and make the deep refiner independent from camera intrinsic
parameters for better cross-domain generalization.
                </p>
            </div>
        </div>
<br>       
        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    Visual Comparison
                </h3>
                <video id="v0" width="100%" autoplay loop muted>
                  <source src="img/visual_compare_video.mp4" type="video/mp4" />
                </video>
                <p class="text-justify">
                    UPNeRF executes pose estimation reliably, fast converging from a random initial
                    pose to the true one, and enables neural reconstruction under diverse object poses, occlusion
                    cases under this cross-dataset setup. UPNeRF is visually
                    compared to the other major competitors, demonstrates sharper rendered image, higher
                    accuracy in shape and pose.                
                </p>
            </div>
        </div>

        <div class="row">
            <div class="col-md-10 col-md-offset-2">
                <h3>
                    Citation
                </h3>
                <div class="form-group col-md-10 col-md-offset-0">
                    <textarea id="bibtex" class="form-control" readonly>
@article{guo2024upnerf,
    title={UPNeRF: A Unified Framework for Monocular 3D Object Reconstruction and Pose Estimation},
    author={Yuliang Guo and Abhinav Kumar and Cheng Zhao and Ruoyu Wang and Xinyu Huang and Liu Ren},
    journal={arXiv},
    year={2024}
}</textarea>
                </div>
            </div>
        </div>

        <!-- <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    Acknowledgements
                </h3>
                <p class="text-justify">
                Thanks to Janne Kontkanen, Rick Szeliski, and David Salesin for their comments on the text, and to Ricardo Martin-Brualla, Keunhong Park, Ben Poole, Aleksander Hołyński, Etienne Pot, Kostas Rematas, Daniel Duckworth, Marcos Seefelder, Cardin Moffett, and Peter Zhizhin for their advice and help.
                    <br><br>
                The website template was borrowed from <a href="http://mgharbi.com/">Michaël Gharbi</a> and <a href="https://dorverbin.github.io/refnerf">Ref-NeRF</a>.
                </p>
            </div>
        </div> -->
    </div>
</body>
</html>
